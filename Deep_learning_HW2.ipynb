{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_learning_HW2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPO2/W1j76gnxHUPgiRdh8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElizavetaNosova/DeepNLP-HSE-homeworks/blob/main/Deep_learning_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwoSiOMzi5-H",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "3f90b538-95bc-425b-b896-01daa3e26881"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aa2d56c9-0bfb-47d8-b25a-70de41aeb080\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aa2d56c9-0bfb-47d8-b25a-70de41aeb080\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data.py to data (1).py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data.py': b\"import os\\r\\nimport time\\r\\nimport requests\\r\\nimport shutil\\r\\nimport gzip\\r\\n\\r\\nfrom typing import Dict, List, Tuple\\r\\n\\r\\nfrom tqdm import tqdm\\r\\n\\r\\nimport pandas as pd\\r\\nfrom sklearn.model_selection import train_test_split\\r\\n\\r\\n\\r\\nclass Downloader:\\r\\n\\r\\n    URLS = {\\r\\n        'single': [\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Appliances.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Arts_Crafts_and_Sewing.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Automotive.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Baby.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Beauty.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Cell_Phones_and_Accessories.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Clothing_Shoes_and_Jewelry.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Electronics.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Grocery_and_Gourmet_Food.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Health_and_Personal_Care.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Home_and_Kitchen.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Industrial_and_Scientific.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Musical_Instruments.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Office_Products.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Patio_Lawn_and_Garden.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Pet_Supplies.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Software.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Sports_and_Outdoors.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Tools_and_Home_Improvement.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Toys_and_Games.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/qa_Video_Games.json.gz'\\r\\n        ],\\r\\n        'multiple': [\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Automotive.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Baby.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Beauty.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Cell_Phones_and_Accessories.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Clothing_Shoes_and_Jewelry.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Electronics.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Grocery_and_Gourmet_Food.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Health_and_Personal_Care.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Home_and_Kitchen.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Musical_Instruments.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Office_Products.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Patio_Lawn_and_Garden.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Pet_Supplies.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Sports_and_Outdoors.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Tools_and_Home_Improvement.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Toys_and_Games.json.gz',\\r\\n            'http://jmcauley.ucsd.edu/data/amazon/qa/icdm/QA_Video_Games.json.gz'\\r\\n        ]\\r\\n    }\\r\\n\\r\\n    def __init__(self,\\r\\n                 data_path: str,\\r\\n                 override: bool = False,\\r\\n                 sleep_time: float = 0.05,\\r\\n                 verbose: bool = True):\\r\\n\\r\\n        self.data_path = data_path\\r\\n        self.override = override\\r\\n        self.sleep_time = sleep_time\\r\\n        self.verbose = verbose\\r\\n\\r\\n    @staticmethod\\r\\n    def make_dir(path: str, override: bool = False):\\r\\n        if override:\\r\\n            shutil.rmtree(path, ignore_errors=True)\\r\\n        try:\\r\\n            os.mkdir(path)\\r\\n        except FileExistsError:\\r\\n            pass\\r\\n\\r\\n    @staticmethod\\r\\n    def download_file(url: str, save_path: str, verbose: bool = False, chunk_size: int = 8192):\\r\\n        try:\\r\\n            filename = save_path.split('/')[-1]\\r\\n            with requests.get(url, stream=True) as request:\\r\\n                request.raise_for_status()\\r\\n                with open(save_path, 'wb') as file_object:\\r\\n                    for chunk in tqdm(request.iter_content(chunk_size=chunk_size),\\r\\n                                      desc=f'Download {filename}',\\r\\n                                      disable=not verbose):\\r\\n                        if chunk:\\r\\n                            file_object.write(chunk)\\r\\n        except KeyboardInterrupt as exception:\\r\\n            os.remove(save_path)\\r\\n            raise exception\\r\\n        except Exception as exception:\\r\\n            os.remove(save_path)\\r\\n            raise exception\\r\\n\\r\\n    def run(self):\\r\\n\\r\\n        self.make_dir(self.data_path, override=self.override)\\r\\n\\r\\n        for key in self.URLS:\\r\\n            for url in tqdm(self.URLS[key], desc=key, disable=not self.verbose):\\r\\n                filename = key + '_' + url.split('/')[-1]\\r\\n\\r\\n                time.sleep(self.sleep_time)\\r\\n\\r\\n                file_path = os.path.join(self.data_path, filename)\\r\\n\\r\\n                if not os.path.isfile(file_path):\\r\\n                    self.download_file(url=url, save_path=file_path, verbose=False)\\r\\n\\r\\n\\r\\nclass Parser:\\r\\n\\r\\n    BAD_CATEGORIES = [\\r\\n        'electronics',\\r\\n        'software',\\r\\n        'appliances',\\r\\n        'industrial and scientific',\\r\\n        'musical instruments',\\r\\n        'arts crafts and sewing',\\r\\n        'video games',\\r\\n        'toys and games',\\r\\n        'clothing shoes and jewelry',\\r\\n        'home and kitchen',\\r\\n        'health and personal care',\\r\\n        'tools and home improvement',\\r\\n        'patio lawn and garden'\\r\\n    ]\\r\\n\\r\\n    def __init__(self,\\r\\n                 data_path: str,\\r\\n                 is_question_classification: bool = True,\\r\\n                 train_samples: int = 250_000,\\r\\n                 valid_samples: int = 50_000,\\r\\n                 lower_threshold: int = 5,\\r\\n                 upper_threshold: int = 512):\\r\\n\\r\\n        self.data_path = data_path\\r\\n        self.is_question_classification = is_question_classification\\r\\n\\r\\n        self.train_samples = train_samples\\r\\n        self.valid_samples = valid_samples\\r\\n\\r\\n        self.lower_threshold = lower_threshold\\r\\n        self.upper_threshold = upper_threshold\\r\\n\\r\\n    @staticmethod\\r\\n    def parse_filename(file_path: str) -> str:\\r\\n        category = file_path.split('/')[-1].split('.')[0]\\r\\n\\r\\n        category = category.lower().replace('qa_', '')\\r\\n        category = category.replace('single_', '').replace('multiple_', '')\\r\\n        category = category.replace('_', ' ')\\r\\n\\r\\n        return category\\r\\n\\r\\n    @staticmethod\\r\\n    def prepare_text(text: str) -> str:\\r\\n        text = text.lower().encode('utf-8', 'ignore').decode('utf-8', 'ignore')\\r\\n\\r\\n        return text\\r\\n\\r\\n    def filter_sample(self, sample: Dict[str, str]) -> bool:\\r\\n\\r\\n        if not (self.lower_threshold <= len(sample['question']) <= self.upper_threshold):\\r\\n            return False\\r\\n\\r\\n        if not (self.lower_threshold <= len(sample['response']) <= self.upper_threshold):\\r\\n            return False\\r\\n\\r\\n        if sample['category'] in self.BAD_CATEGORIES:\\r\\n            return False\\r\\n\\r\\n        return True\\r\\n\\r\\n    def parse_single_sample(self,\\r\\n                            sample: Dict,\\r\\n                            category: str,\\r\\n                            with_types: bool = False) -> List[Dict[str, str]]:\\r\\n\\r\\n        result_sample = {\\r\\n            'question': self.prepare_text(sample['question']),\\r\\n            'response': self.prepare_text(sample['answer']),\\r\\n            'category': category\\r\\n        }\\r\\n\\r\\n        if with_types:\\r\\n            result_sample['question_type'] = sample['questionType']\\r\\n            result_sample['answer_type'] = sample['answerType']\\r\\n\\r\\n        result_sample = [result_sample] if self.filter_sample(result_sample) else list()\\r\\n\\r\\n        return result_sample\\r\\n\\r\\n    def parse_multiple_sample(self,\\r\\n                              sample: Dict,\\r\\n                              category: str) -> List[Dict[str, str]]:\\r\\n\\r\\n        result_samples: List[Dict[str, str]] = list()\\r\\n\\r\\n        for question_data in sample['questions']:\\r\\n            for answer_data in question_data['answers']:\\r\\n                parsed_sample = {\\r\\n                    'question': self.prepare_text(question_data['questionText']),\\r\\n                    'response': self.prepare_text(answer_data['answerText']),\\r\\n                    'category': category,\\r\\n                }\\r\\n                if self.filter_sample(parsed_sample):\\r\\n                    result_samples.append(parsed_sample)\\r\\n\\r\\n        return result_samples\\r\\n\\r\\n    def get_file_paths(self):\\r\\n\\r\\n        return [os.path.join(self.data_path, file)\\r\\n                for file in os.listdir(self.data_path)\\r\\n                if file.endswith('.json.gz')]\\r\\n\\r\\n    def read_data(self) -> List[Dict[str, str]]:\\r\\n\\r\\n        file_paths = self.get_file_paths()\\r\\n\\r\\n        data: List[Dict[str, str]] = list()\\r\\n\\r\\n        for file_path in tqdm(file_paths, desc='Reading'):\\r\\n            with gzip.open(file_path) as file_object:\\r\\n                for sample in file_object:\\r\\n                    sample = eval(sample)\\r\\n                    category = self.parse_filename(file_path)\\r\\n\\r\\n                    if 'single' in file_path:\\r\\n                        data.extend(self.parse_single_sample(sample, category))\\r\\n                    elif 'multiple' in file_path:\\r\\n                        data.extend(self.parse_multiple_sample(sample, category))\\r\\n\\r\\n        return data\\r\\n\\r\\n    def run(self) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\\r\\n\\r\\n        data = pd.DataFrame(self.read_data())\\r\\n\\r\\n        subset = ['question']\\r\\n\\r\\n        if not self.is_question_classification:\\r\\n            subset.append('response')\\r\\n\\r\\n        data = data.drop_duplicates(subset=subset)\\r\\n\\r\\n        data = data.sample(frac=1)\\r\\n\\r\\n        if self.train_samples + self.valid_samples >= data.shape[0]:\\r\\n            raise ValueError('Sum of train_samples and valid_samples must be less than length of data')\\r\\n\\r\\n        data, valid = train_test_split(data, stratify=data.category, test_size=self.valid_samples)\\r\\n\\r\\n        unlabeled, train = train_test_split(data, stratify=data.category, test_size=self.train_samples)\\r\\n\\r\\n        unlabeled = unlabeled[['question', 'response']]\\r\\n\\r\\n        unlabeled.reset_index(inplace=True, drop=True)\\r\\n        train.reset_index(inplace=True, drop=True)\\r\\n        valid.reset_index(inplace=True, drop=True)\\r\\n\\r\\n        return unlabeled, train, valid\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNqWmDKnjINR"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from data import Downloader, Parser"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_sbAT1hjL3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b94040e-171f-46af-d543-6d84f29c05fa"
      },
      "source": [
        "# раскомментируйте и скачайте\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-04 10:43:16--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip.5’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  31.0MB/s    in 21s     \n",
            "\n",
            "2021-04-04 10:43:38 (30.4 MB/s) - ‘wiki-news-300d-1M.vec.zip.5’ saved [681808098/681808098]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgWPX-QVjQJ9"
      },
      "source": [
        "# путь к данным\n",
        "data_path = './data/'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UymEeD0xjV5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f8ef36-1ddf-40a9-bc5d-834783dcbb63"
      },
      "source": [
        "downloader = Downloader(data_path=data_path)\n",
        "downloader.run()\n",
        "parser = Parser(data_path=data_path)\n",
        "unlabeled, train, valid = parser.run()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "single: 100%|██████████| 21/21 [00:01<00:00, 19.65it/s]\n",
            "multiple: 100%|██████████| 17/17 [00:00<00:00, 19.67it/s]\n",
            "Reading: 100%|██████████| 38/38 [02:23<00:00,  3.78s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR_XPUpgjhPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243866de-3cea-4c85-81a9-5f073f02f69b"
      },
      "source": [
        "# проверим, что в трейне и валидации одинаковые категории\n",
        "set(train.category.unique().tolist()) == set(valid.category.unique().tolist())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WexFVkE4jpOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c4b131-f52d-4e28-f507-e5098ea94ddc"
      },
      "source": [
        "unique_categories = set(train.category.unique().tolist() + valid.category.unique().tolist())\n",
        "category2index = {category: index for index, category in enumerate(unique_categories)}\n",
        "category2index"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'automotive': 6,\n",
              " 'baby': 0,\n",
              " 'beauty': 4,\n",
              " 'cell phones and accessories': 3,\n",
              " 'grocery and gourmet food': 1,\n",
              " 'office products': 2,\n",
              " 'pet supplies': 5,\n",
              " 'sports and outdoors': 7}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUT5wTavj0rz"
      },
      "source": [
        "train['target'] = train.category.map(category2index)\n",
        "valid['target'] = valid.category.map(category2index)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgHA57cNj2Qp"
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, texts, targets):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text = self.texts[index]\n",
        "        target = self.targets[index]\n",
        "        \n",
        "        return text, target"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amJk1SShkA3g"
      },
      "source": [
        "# подготовим данные\n",
        "train_x = list(train.question)\n",
        "train_y = list(train.target)\n",
        "\n",
        "valid_x = list(valid.question)\n",
        "valid_y = list(valid.target)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY2Nw0mMlcD_"
      },
      "source": [
        "import zipfile\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_embeddings(zip_path, filename, pad_token='PAD', max_words=100_000, verbose=True):\n",
        "    \n",
        "    vocab = dict()\n",
        "    embeddings = list()\n",
        "\n",
        "    with zipfile.ZipFile(zip_path) as zipped_file:\n",
        "        with zipped_file.open(filename) as file_object:\n",
        "\n",
        "            vocab_size, embedding_dim = file_object.readline().decode('utf-8').strip().split()\n",
        "\n",
        "            vocab_size = int(vocab_size)\n",
        "            embedding_dim = int(embedding_dim)\n",
        "            \n",
        "            # в файле 1 000 000 слов с векторами, давайте ограничим для простоты этот словарь\n",
        "            max_words = vocab_size if max_words <= 0 else max_words \n",
        "            \n",
        "            # добавим пад токен и эмбеддинг в нашу матрицу эмбеддингов и словарь\n",
        "            vocab[pad_token] = len(vocab)\n",
        "            embeddings.append(np.zeros(embedding_dim))\n",
        "\n",
        "            progress_bar = tqdm(total=max_words, disable=not verbose)\n",
        "\n",
        "            for line in file_object:\n",
        "                parts = line.decode('utf-8').strip().split()\n",
        "\n",
        "                token = ' '.join(parts[:-embedding_dim]).lower()\n",
        "                \n",
        "                if token in vocab:\n",
        "                    continue\n",
        "                \n",
        "                word_vector = np.array(list(map(float, parts[-embedding_dim:])))\n",
        "\n",
        "                vocab[token] = len(vocab)\n",
        "                embeddings.append(word_vector)\n",
        "\n",
        "                progress_bar.update()\n",
        "                \n",
        "                if len(vocab) == max_words:\n",
        "                    break\n",
        "\n",
        "            progress_bar.close()\n",
        "\n",
        "    embeddings = np.stack(embeddings)\n",
        "    \n",
        "    return vocab, embeddings"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga5tMz8Tloow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2ec85f-670d-403e-f1ba-c77af2caa9a9"
      },
      "source": [
        "vocab, embeddings = load_embeddings('./wiki-news-300d-1M.vec.zip.5', 'wiki-news-300d-1M.vec', max_words=100_000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 99999/100000 [00:11<00:00, 8543.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Ms9XGDGB-j"
      },
      "source": [
        "embeddings = torch.tensor(embeddings).double()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcdlvYmilsg4"
      },
      "source": [
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1YLKwQ_l0nY"
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, texts, targets, vocab, pad_index=0, max_length=32):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        self.vocab = vocab\n",
        "        \n",
        "        self.pad_index = pad_index\n",
        "        self.max_length = max_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def tokenization(self, text):\n",
        "        \n",
        "        tokens = wordpunct_tokenize(text)\n",
        "        \n",
        "        token_indices = [self.vocab[tok] for tok in tokens if tok in self.vocab]\n",
        "        \n",
        "        return token_indices\n",
        "    \n",
        "    def padding(self, tokenized_text):\n",
        "        \n",
        "        tokenized_text = tokenized_text[:self.max_length]\n",
        "        \n",
        "        tokenized_text += [self.pad_index] * (self.max_length - len(tokenized_text))\n",
        "        \n",
        "        return tokenized_text\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text = self.texts[index]        \n",
        "        target = self.targets[index]\n",
        "        \n",
        "        tokenized_text = self.tokenization(text)\n",
        "        tokenized_text = self.padding(tokenized_text)\n",
        "        \n",
        "        tokenized_text = torch.tensor(tokenized_text)\n",
        "        \n",
        "        return tokenized_text, target"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztJ5f9X6l9p8"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=train_x, targets=train_y, vocab=vocab)\n",
        "valid_dataset = TextClassificationDataset(texts=valid_x, targets=valid_y, vocab=vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=128)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwqXsNlf7vqu"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from statistics import mean"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwqRihOtHNKy",
        "outputId": "ac13b6c4-59bb-428d-8c46-f0f2299724d3"
      },
      "source": [
        "embeddings.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100000, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NQbEq0zHZAX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIBf_x-gRLRM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_njm7fk4mat9"
      },
      "source": [
        "class DeepAverageNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self, embeddings, n_classes):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=embeddings.shape[-1])\n",
        "\n",
        "        self.cnn_1_1 = torch.nn.Conv1d(in_channels=300, out_channels=200, kernel_size=5)\n",
        "        self.cnn_1_2 = torch.nn.Conv1d(in_channels=200, out_channels=200, kernel_size=3)\n",
        "\n",
        "        self.cnn_2_1 = torch.nn.Conv1d(in_channels=200, out_channels=100, kernel_size=2)\n",
        "        self.cnn_2_2 = torch.nn.Conv1d(in_channels=200, out_channels=100, kernel_size=4)\n",
        "\n",
        "        self.max_pooling_kernel2 =torch.nn.MaxPool1d(kernel_size = 2)\n",
        "\n",
        "        self.cnn_n_classes = torch.nn.Conv1d(in_channels = 200, out_channels=n_classes, kernel_size=1)\n",
        "        #я ожидала, что в лстм надо передавать количество классов\n",
        "        self.lstm = torch.nn.LSTM(input_size=13, hidden_size=13, bidirectional=True, batch_first=True, num_layers=1)\n",
        "        self.final_pooling = torch.nn.MaxPool1d(kernel_size = 13) #для прохода вперед и назад берем максимум\n",
        "\n",
        "        self.train_losses = []\n",
        "        self.train_epoch_losses = []\n",
        "        self.valid_epoch_losses = []\n",
        "\n",
        "        self.train_f1 = []\n",
        "        self.train_epoch_f1 = []\n",
        "        self.valid_epoch_f1 = []\n",
        "\n",
        "\n",
        "       \n",
        "    def forward(self, x):\n",
        "        x = self.embedding_layer(x)\n",
        "        x = x.transpose(-1, -2)\n",
        "        x = self.batch_norm(x)\n",
        "\n",
        "        x = self.cnn_1_1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = torch.cat((self.cnn_1_2(x), torch.zeros(x.size(0), 200, 2).cuda()), dim=2) + x\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        #применяем паралельные свертки\n",
        "        \n",
        "        x = torch.cat((self.max_pooling_kernel2(self.cnn_2_1(x)),  torch.cat((self.max_pooling_kernel2(self.cnn_2_2(x)), torch.zeros(x.size(0), 100, 1).cuda()), dim=2)), dim=1)\n",
        "\n",
        "        x = self.cnn_n_classes(x)\n",
        "\n",
        "        x = self.lstm(x)[0]\n",
        "        x = self.final_pooling(x)\n",
        "        x = torch.mean(x,  2) \n",
        "        return x\n",
        "\n",
        "\n",
        "    def train_epoch(self, train_loader, use_cuda=True):\n",
        "        self.train()\n",
        "        self.current_epoch_iterations = 0\n",
        "        for x, y in tqdm(train_loader):\n",
        "            if use_cuda:\n",
        "                x = x.cuda()\n",
        "                y = y.cuda()\n",
        "            output = self.forward(x)\n",
        "            loss = criterion(output, y)\n",
        "            self.train_losses.append(float(loss))\n",
        "            predictions = torch.softmax(output, 1).cpu()\n",
        "            self.train_f1.append(f1_score(torch.max(predictions, 1)[1], y.cpu(), average='macro'))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            self.current_epoch_iterations  += 1\n",
        "\n",
        "    def valid(self, valid_loader, max_valid_iterations=50, use_cuda=True):\n",
        "        valid_losses = []\n",
        "        valid_f1 = []\n",
        "        n_valid=0\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            for x, y in valid_loader:\n",
        "                if use_cuda:\n",
        "                    x = x.cuda()\n",
        "                    y = y.cuda()\n",
        "                output = self.forward(x)\n",
        "                loss = criterion(output, y)\n",
        "                valid_losses.append(float(loss))\n",
        "                predictions = torch.softmax(output, 1).cpu()\n",
        "                valid_f1.append(f1_score(torch.max(predictions, 1)[1], y.cpu(), average='macro'))\n",
        "                n_valid += 1\n",
        "                if n_valid == max_valid_iterations:\n",
        "                    break\n",
        "        self.valid_epoch_losses.append(mean(valid_losses))\n",
        "        self.valid_epoch_f1.append(mean(valid_f1))\n",
        "\n",
        "    def train_and_valid(self, train_loader, valid_loader, n_epochs=10, use_cuda=True):\n",
        "        for epoch in range(n_epochs):\n",
        "            self.train_epoch(train_loader, use_cuda)\n",
        "            mean_train_loss = mean(self.train_losses[-self.current_epoch_iterations:])\n",
        "            self.train_epoch_losses.append(mean_train_loss)\n",
        "            self.train_epoch_f1.append(mean(self.train_f1[-self.current_epoch_iterations:]))\n",
        "            self.valid(valid_loader, use_cuda)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7ZsJV_5GtWh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgbpdR0tvVJv"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "test_model = DeepAverageNetwork(embeddings=embeddings, n_classes=len(category2index))\n",
        "test_model.double()\n",
        "test_model.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam([ {'params': test_model.embedding_layer.parameters(), 'lr': 1e-6},\n",
        "                              {'params': test_model.cnn_1_2.parameters()},\n",
        "                              {'params': test_model.cnn_2_1.parameters()},\n",
        "                              {'params': test_model.cnn_2_2.parameters()},\n",
        "                              {'params': test_model.lstm.parameters()}], \n",
        "                               lr = 1e-3)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUN_l91q3e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "56f87d43-9ea4-4af1-abe6-d30946b9e8d5"
      },
      "source": [
        "test_model.train_and_valid(train_loader, valid_loader)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1954/1954 [06:52<00:00,  4.74it/s]\n",
            "100%|██████████| 1954/1954 [06:52<00:00,  4.74it/s]\n",
            "100%|██████████| 1954/1954 [06:52<00:00,  4.74it/s]\n",
            "100%|██████████| 1954/1954 [06:52<00:00,  4.74it/s]\n",
            "100%|██████████| 1954/1954 [06:51<00:00,  4.74it/s]\n",
            "100%|██████████| 1954/1954 [06:51<00:00,  4.75it/s]\n",
            "100%|██████████| 1954/1954 [06:51<00:00,  4.75it/s]\n",
            " 10%|█         | 203/1954 [00:42<06:09,  4.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4b0ae6a60b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-3a819079773c>\u001b[0m in \u001b[0;36mtrain_and_valid\u001b[0;34m(self, train_loader, valid_loader, n_epochs, use_cuda)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_and_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mmean_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch_iterations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_train_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-3a819079773c>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, train_loader, use_cuda)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-3a819079773c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ShFd9tLb5S0",
        "outputId": "039512b9-f3e1-4cd6-dcb4-450b9157611d"
      },
      "source": [
        "correct = []\n",
        "predicted = []\n",
        "test_model.eval()\n",
        "with torch.no_grad():\n",
        "    for x, y in tqdm(valid_loader):\n",
        "        correct += [int(i) for i in y]\n",
        "        x = x.cuda()\n",
        "        prediction = test_model(x).argmax(1)\n",
        "        predicted += [int(i) for i in prediction]\n",
        "        "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 3/391 [00:00<00:18, 21.46it/s]\u001b[A\n",
            "  2%|▏         | 6/391 [00:00<00:17, 21.45it/s]\u001b[A\n",
            "  2%|▏         | 9/391 [00:00<00:17, 21.63it/s]\u001b[A\n",
            "  3%|▎         | 12/391 [00:00<00:17, 22.11it/s]\u001b[A\n",
            "  4%|▍         | 15/391 [00:00<00:16, 22.42it/s]\u001b[A\n",
            "  5%|▍         | 18/391 [00:00<00:16, 22.78it/s]\u001b[A\n",
            "  5%|▌         | 21/391 [00:00<00:16, 23.01it/s]\u001b[A\n",
            "  6%|▌         | 24/391 [00:01<00:15, 23.21it/s]\u001b[A\n",
            "  7%|▋         | 27/391 [00:01<00:15, 23.24it/s]\u001b[A\n",
            "  8%|▊         | 30/391 [00:01<00:15, 23.20it/s]\u001b[A\n",
            "  8%|▊         | 33/391 [00:01<00:15, 23.18it/s]\u001b[A\n",
            "  9%|▉         | 36/391 [00:01<00:15, 23.21it/s]\u001b[A\n",
            " 10%|▉         | 39/391 [00:01<00:15, 23.13it/s]\u001b[A\n",
            " 11%|█         | 42/391 [00:01<00:15, 23.17it/s]\u001b[A\n",
            " 12%|█▏        | 45/391 [00:01<00:14, 23.47it/s]\u001b[A\n",
            " 12%|█▏        | 48/391 [00:02<00:14, 23.43it/s]\u001b[A\n",
            " 13%|█▎        | 51/391 [00:02<00:14, 23.58it/s]\u001b[A\n",
            " 14%|█▍        | 54/391 [00:02<00:14, 23.61it/s]\u001b[A\n",
            " 15%|█▍        | 57/391 [00:02<00:14, 23.52it/s]\u001b[A\n",
            " 15%|█▌        | 60/391 [00:02<00:14, 23.44it/s]\u001b[A\n",
            " 16%|█▌        | 63/391 [00:02<00:14, 23.39it/s]\u001b[A\n",
            " 17%|█▋        | 66/391 [00:02<00:13, 23.49it/s]\u001b[A\n",
            " 18%|█▊        | 69/391 [00:02<00:13, 23.61it/s]\u001b[A\n",
            " 18%|█▊        | 72/391 [00:03<00:13, 23.73it/s]\u001b[A\n",
            " 19%|█▉        | 75/391 [00:03<00:13, 23.75it/s]\u001b[A\n",
            " 20%|█▉        | 78/391 [00:03<00:13, 23.82it/s]\u001b[A\n",
            " 21%|██        | 81/391 [00:03<00:12, 23.88it/s]\u001b[A\n",
            " 21%|██▏       | 84/391 [00:03<00:12, 23.69it/s]\u001b[A\n",
            " 22%|██▏       | 87/391 [00:03<00:12, 23.49it/s]\u001b[A\n",
            " 23%|██▎       | 90/391 [00:03<00:12, 23.51it/s]\u001b[A\n",
            " 24%|██▍       | 93/391 [00:03<00:12, 23.05it/s]\u001b[A\n",
            " 25%|██▍       | 96/391 [00:04<00:12, 23.11it/s]\u001b[A\n",
            " 25%|██▌       | 99/391 [00:04<00:12, 23.12it/s]\u001b[A\n",
            " 26%|██▌       | 102/391 [00:04<00:12, 22.89it/s]\u001b[A\n",
            " 27%|██▋       | 105/391 [00:04<00:12, 23.08it/s]\u001b[A\n",
            " 28%|██▊       | 108/391 [00:04<00:12, 23.21it/s]\u001b[A\n",
            " 28%|██▊       | 111/391 [00:04<00:11, 23.34it/s]\u001b[A\n",
            " 29%|██▉       | 114/391 [00:04<00:12, 23.03it/s]\u001b[A\n",
            " 30%|██▉       | 117/391 [00:05<00:11, 23.08it/s]\u001b[A\n",
            " 31%|███       | 120/391 [00:05<00:11, 23.25it/s]\u001b[A\n",
            " 31%|███▏      | 123/391 [00:05<00:11, 23.32it/s]\u001b[A\n",
            " 32%|███▏      | 126/391 [00:05<00:11, 23.49it/s]\u001b[A\n",
            " 33%|███▎      | 129/391 [00:05<00:11, 23.51it/s]\u001b[A\n",
            " 34%|███▍      | 132/391 [00:05<00:10, 23.56it/s]\u001b[A\n",
            " 35%|███▍      | 135/391 [00:05<00:10, 23.55it/s]\u001b[A\n",
            " 35%|███▌      | 138/391 [00:05<00:10, 23.72it/s]\u001b[A\n",
            " 36%|███▌      | 141/391 [00:06<00:10, 23.76it/s]\u001b[A\n",
            " 37%|███▋      | 144/391 [00:06<00:10, 23.83it/s]\u001b[A\n",
            " 38%|███▊      | 147/391 [00:06<00:10, 23.74it/s]\u001b[A\n",
            " 38%|███▊      | 150/391 [00:06<00:10, 23.77it/s]\u001b[A\n",
            " 39%|███▉      | 153/391 [00:06<00:10, 23.76it/s]\u001b[A\n",
            " 40%|███▉      | 156/391 [00:06<00:09, 23.82it/s]\u001b[A\n",
            " 41%|████      | 159/391 [00:06<00:09, 23.80it/s]\u001b[A\n",
            " 41%|████▏     | 162/391 [00:06<00:09, 23.76it/s]\u001b[A\n",
            " 42%|████▏     | 165/391 [00:07<00:09, 23.81it/s]\u001b[A\n",
            " 43%|████▎     | 168/391 [00:07<00:09, 23.70it/s]\u001b[A\n",
            " 44%|████▎     | 171/391 [00:07<00:09, 23.74it/s]\u001b[A\n",
            " 45%|████▍     | 174/391 [00:07<00:09, 23.81it/s]\u001b[A\n",
            " 45%|████▌     | 177/391 [00:07<00:08, 23.80it/s]\u001b[A\n",
            " 46%|████▌     | 180/391 [00:07<00:08, 23.87it/s]\u001b[A\n",
            " 47%|████▋     | 183/391 [00:07<00:08, 23.93it/s]\u001b[A\n",
            " 48%|████▊     | 186/391 [00:07<00:08, 23.95it/s]\u001b[A\n",
            " 48%|████▊     | 189/391 [00:08<00:08, 23.91it/s]\u001b[A\n",
            " 49%|████▉     | 192/391 [00:08<00:08, 23.88it/s]\u001b[A\n",
            " 50%|████▉     | 195/391 [00:08<00:08, 23.85it/s]\u001b[A\n",
            " 51%|█████     | 198/391 [00:08<00:08, 23.84it/s]\u001b[A\n",
            " 51%|█████▏    | 201/391 [00:08<00:07, 23.84it/s]\u001b[A\n",
            " 52%|█████▏    | 204/391 [00:08<00:07, 23.80it/s]\u001b[A\n",
            " 53%|█████▎    | 207/391 [00:08<00:07, 23.64it/s]\u001b[A\n",
            " 54%|█████▎    | 210/391 [00:08<00:07, 23.56it/s]\u001b[A\n",
            " 54%|█████▍    | 213/391 [00:09<00:07, 23.40it/s]\u001b[A\n",
            " 55%|█████▌    | 216/391 [00:09<00:07, 23.46it/s]\u001b[A\n",
            " 56%|█████▌    | 219/391 [00:09<00:07, 23.52it/s]\u001b[A\n",
            " 57%|█████▋    | 222/391 [00:09<00:07, 23.25it/s]\u001b[A\n",
            " 58%|█████▊    | 225/391 [00:09<00:07, 23.42it/s]\u001b[A\n",
            " 58%|█████▊    | 228/391 [00:09<00:06, 23.49it/s]\u001b[A\n",
            " 59%|█████▉    | 231/391 [00:09<00:06, 23.48it/s]\u001b[A\n",
            " 60%|█████▉    | 234/391 [00:09<00:06, 23.08it/s]\u001b[A\n",
            " 61%|██████    | 237/391 [00:10<00:06, 23.15it/s]\u001b[A\n",
            " 61%|██████▏   | 240/391 [00:10<00:06, 23.36it/s]\u001b[A\n",
            " 62%|██████▏   | 243/391 [00:10<00:06, 23.36it/s]\u001b[A\n",
            " 63%|██████▎   | 246/391 [00:10<00:06, 23.38it/s]\u001b[A\n",
            " 64%|██████▎   | 249/391 [00:10<00:06, 23.49it/s]\u001b[A\n",
            " 64%|██████▍   | 252/391 [00:10<00:05, 23.49it/s]\u001b[A\n",
            " 65%|██████▌   | 255/391 [00:10<00:05, 23.57it/s]\u001b[A\n",
            " 66%|██████▌   | 258/391 [00:11<00:05, 23.46it/s]\u001b[A\n",
            " 67%|██████▋   | 261/391 [00:11<00:05, 23.43it/s]\u001b[A\n",
            " 68%|██████▊   | 264/391 [00:11<00:05, 23.52it/s]\u001b[A\n",
            " 68%|██████▊   | 267/391 [00:11<00:05, 23.41it/s]\u001b[A\n",
            " 69%|██████▉   | 270/391 [00:11<00:05, 23.32it/s]\u001b[A\n",
            " 70%|██████▉   | 273/391 [00:11<00:05, 23.27it/s]\u001b[A\n",
            " 71%|███████   | 276/391 [00:11<00:04, 23.12it/s]\u001b[A\n",
            " 71%|███████▏  | 279/391 [00:11<00:04, 23.10it/s]\u001b[A\n",
            " 72%|███████▏  | 282/391 [00:12<00:04, 23.09it/s]\u001b[A\n",
            " 73%|███████▎  | 285/391 [00:12<00:04, 22.94it/s]\u001b[A\n",
            " 74%|███████▎  | 288/391 [00:12<00:04, 22.96it/s]\u001b[A\n",
            " 74%|███████▍  | 291/391 [00:12<00:04, 23.00it/s]\u001b[A\n",
            " 75%|███████▌  | 294/391 [00:12<00:04, 23.02it/s]\u001b[A\n",
            " 76%|███████▌  | 297/391 [00:12<00:04, 23.17it/s]\u001b[A\n",
            " 77%|███████▋  | 300/391 [00:12<00:03, 23.09it/s]\u001b[A\n",
            " 77%|███████▋  | 303/391 [00:12<00:03, 23.27it/s]\u001b[A\n",
            " 78%|███████▊  | 306/391 [00:13<00:03, 23.29it/s]\u001b[A\n",
            " 79%|███████▉  | 309/391 [00:13<00:03, 23.49it/s]\u001b[A\n",
            " 80%|███████▉  | 312/391 [00:13<00:03, 23.52it/s]\u001b[A\n",
            " 81%|████████  | 315/391 [00:13<00:03, 23.63it/s]\u001b[A\n",
            " 81%|████████▏ | 318/391 [00:13<00:03, 23.65it/s]\u001b[A\n",
            " 82%|████████▏ | 321/391 [00:13<00:02, 23.73it/s]\u001b[A\n",
            " 83%|████████▎ | 324/391 [00:13<00:02, 23.73it/s]\u001b[A\n",
            " 84%|████████▎ | 327/391 [00:13<00:02, 23.71it/s]\u001b[A\n",
            " 84%|████████▍ | 330/391 [00:14<00:02, 23.71it/s]\u001b[A\n",
            " 85%|████████▌ | 333/391 [00:14<00:02, 23.69it/s]\u001b[A\n",
            " 86%|████████▌ | 336/391 [00:14<00:02, 23.68it/s]\u001b[A\n",
            " 87%|████████▋ | 339/391 [00:14<00:02, 23.70it/s]\u001b[A\n",
            " 87%|████████▋ | 342/391 [00:14<00:02, 23.72it/s]\u001b[A\n",
            " 88%|████████▊ | 345/391 [00:14<00:01, 23.77it/s]\u001b[A\n",
            " 89%|████████▉ | 348/391 [00:14<00:01, 23.61it/s]\u001b[A\n",
            " 90%|████████▉ | 351/391 [00:14<00:01, 23.63it/s]\u001b[A\n",
            " 91%|█████████ | 354/391 [00:15<00:01, 23.58it/s]\u001b[A\n",
            " 91%|█████████▏| 357/391 [00:15<00:01, 23.58it/s]\u001b[A\n",
            " 92%|█████████▏| 360/391 [00:15<00:01, 23.67it/s]\u001b[A\n",
            " 93%|█████████▎| 363/391 [00:15<00:01, 23.64it/s]\u001b[A\n",
            " 94%|█████████▎| 366/391 [00:15<00:01, 23.67it/s]\u001b[A\n",
            " 94%|█████████▍| 369/391 [00:15<00:00, 23.51it/s]\u001b[A\n",
            " 95%|█████████▌| 372/391 [00:15<00:00, 23.63it/s]\u001b[A\n",
            " 96%|█████████▌| 375/391 [00:15<00:00, 23.57it/s]\u001b[A\n",
            " 97%|█████████▋| 378/391 [00:16<00:00, 23.57it/s]\u001b[A\n",
            " 97%|█████████▋| 381/391 [00:16<00:00, 23.47it/s]\u001b[A\n",
            " 98%|█████████▊| 384/391 [00:16<00:00, 23.53it/s]\u001b[A\n",
            " 99%|█████████▉| 387/391 [00:16<00:00, 23.54it/s]\u001b[A\n",
            "100%|██████████| 391/391 [00:16<00:00, 23.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "4T47c1HrsaI9",
        "outputId": "db5aec38-5bde-45fd-92db-566451baa387"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(correct, predicted)\n",
        "\n",
        "import pylab as pl\n",
        "pl.matshow(cm)\n",
        "pl.title('Confusion matrix of the classifier')\n",
        "pl.colorbar()\n",
        "pl.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaQffYArtvR6"
      },
      "source": [
        "Видно, что результат отличный от случайного угадывания наблюдается для всех классов (светлая диагональ). В исходных данных был дисбаланс классов (преобладал седьмой)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}